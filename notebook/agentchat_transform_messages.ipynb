{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25dbbafd-a786-4d63-a29c-3c7fce2582bb",
   "metadata": {},
   "source": [
    "# Preprocessing Chat History with `TransformMessages`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7549a27-bc4a-4609-bb25-cc7d95cf8c23",
   "metadata": {},
   "source": [
    "### This notebook illustrates how to handle long contexts, handle sensitive data, and more by giving the `TransfromMessages` ability to any `ConversableAgent`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce019f5-fccc-430d-9fdc-881aa2c74d3e",
   "metadata": {},
   "source": [
    "We first need to make sure you have the right dependencies installed. If you are installing autogen from source, run the following command inside the base directory:\n",
    "\n",
    "`pip install -e .`\n",
    "\n",
    "If you're not installing autogen from source, run the following command:\n",
    "\n",
    "`pip install pyautogen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47773f79-c0fd-4993-bc6e-3d1a57690118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import autogen\n",
    "from autogen.agentchat.contrib.capabilities import transform_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f09246b-a7d0-4238-b62c-1e72c7d815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your llm config\n",
    "llm_config = {\n",
    "    \"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"api_key\": os.environ.get(\"OAI_API_KEY\")}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d0e5ad-8b35-4b30-847e-4723e9c76f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your agent; the user proxy and an assistant\n",
    "assistant = autogen.AssistantAgent(\n",
    "    \"assistant\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\"),\n",
    "    max_consecutive_auto_reply=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180aa953-45be-469a-a94f-0ed0b4ef5ddf",
   "metadata": {},
   "source": [
    "### Handling Long Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6b634-dc0c-4ff3-82c3-59e6f4a82ef1",
   "metadata": {},
   "source": [
    "Imagine a scenario where the LLM generates an extensive amount of text, surpassing the token limit imposed by your API provider. To address this issue, you can leverage `TransformMessages` along with its constituent transformations, `MaxMessagesTransform` and `TruncateMessageTransform`.\n",
    "\n",
    "- `MaxMessagesTransform`: allows you to restrict the total number of messages considered as context history. This capability is particularly useful when you want to limit the conversational context to a specific number of recent messages, ensuring efficient processing and response generation.\n",
    "- `TruncateMessageTransform`: enables you to cap the total number of tokens, either on a per-message basis or across the entire context history. This transformation is invaluable when you need to adhere to strict token limits imposed by your API provider, preventing unnecessary costs or errors caused by exceeding the allowed token count.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b943a2-ec58-41bc-a449-d9118c4bbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the message history to the 3 most recent messages\n",
    "max_msg_transfrom = transform_messages.MaxMessagesTransform(max_messages=3)\n",
    "\n",
    "# Limit the token limit per message to 10 tokens\n",
    "token_limit_transform = transform_messages.TokenLimitTransform(max_tokens_per_message=10)\n",
    "\n",
    "# Create the ability and add it to the assistant\n",
    "msg_transform_ability = transform_messages.TransformMessages(transforms=[max_msg_transfrom, token_limit_transform])\n",
    "msg_transform_ability.add_to_agent(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af83518a-88bc-487c-a2be-3b5e5b877344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of messages: 11\n",
      "[{'content': 'Message num: 0', 'role': 'user'}, {'content': 'Message num: 1', 'role': 'user'}, {'content': 'Message num: 2', 'role': 'user'}, {'content': 'Message num: 3', 'role': 'user'}, {'content': 'Message num: 4', 'role': 'user'}, {'content': 'Message num: 5', 'role': 'user'}, {'content': 'Message num: 6', 'role': 'user'}, {'content': 'Message num: 7', 'role': 'user'}, {'content': 'Message num: 8', 'role': 'user'}, {'content': 'Message num: 9', 'role': 'user'}, {'content': 'Message num: 10', 'role': 'user'}]\n",
      "len of messages: 3\n"
     ]
    }
   ],
   "source": [
    "# Let's send few messages to the assistant\n",
    "for i in range(10):\n",
    "    user_proxy.send(f\"Message num: {i}\", assistant, request_reply=False, silent=True)\n",
    "user_proxy.send(f\"Message num: {10}\", assistant, request_reply=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a2ead4-5f8b-4108-b1f0-3b51b41e2231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Message num: 0', 'role': 'user'},\n",
      " {'content': 'Message num: 1', 'role': 'user'},\n",
      " {'content': 'Message num: 2', 'role': 'user'},\n",
      " {'content': 'Message num: 3', 'role': 'user'},\n",
      " {'content': 'Message num: 4', 'role': 'user'},\n",
      " {'content': 'Message num: 5', 'role': 'user'},\n",
      " {'content': 'Message num: 6', 'role': 'user'},\n",
      " {'content': 'Message num: 7', 'role': 'user'},\n",
      " {'content': 'Message num: 8', 'role': 'user'},\n",
      " {'content': 'Message num: 9', 'role': 'user'},\n",
      " {'content': 'Message num: 10', 'role': 'user'},\n",
      " {'content': 'I see that the message numbers are increasing by 1 each time. To '\n",
      "             'continue the pattern, the next message number should be 11.\\n'\n",
      "             '\\n'\n",
      "             'TERMINATE',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(assistant.chat_messages[user_proxy])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
