{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae1f50ec",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_websockets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a71fa36",
   "metadata": {},
   "source": [
    "# Websockets: streaming with websockets\n",
    "\n",
    "## Requirements\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Some extra dependencies are needed for this notebook, which can be installed via pip:\n",
    "\n",
    "```bash\n",
    "pip install pyautogen[websockets] fastapi uvicorn\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ebd2397",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca301a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from websockets.sync.client import connect as ws_connect\n",
    "\n",
    "import autogen\n",
    "from autogen.cache import Cache\n",
    "from autogen.io.websockets import IOStream, IOWebsockets\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(config_list[0][\"model\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92fde41f",
   "metadata": {},
   "source": [
    "````{=mdx}\n",
    ":::tip\n",
    "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b9526e7",
   "metadata": {},
   "source": [
    "## Defining on_connect function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb85afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_connect(iostream: IOWebsockets) -> None:\n",
    "    with IOStream.set_default(iostream):\n",
    "        print(f\" - on_connect(): Connected to client using IOWebsockets {iostream}\", flush=True)\n",
    "\n",
    "        print(\" - on_connect(): Receiving message from client.\", flush=True)\n",
    "\n",
    "        initial_msg = iostream.input()\n",
    "\n",
    "        llm_config = {\n",
    "            \"config_list\": config_list,\n",
    "            \"stream\": True,\n",
    "        }\n",
    "\n",
    "        agent = autogen.ConversableAgent(\n",
    "            name=\"chatbot\",\n",
    "            system_message=\"Complete a task given to you and reply TERMINATE when the task is done. If asked about the weather, use tool weather_forecast(city) to get the weather forecast for a city.\",\n",
    "            llm_config=llm_config,\n",
    "        )\n",
    "\n",
    "        # create a UserProxyAgent instance named \"user_proxy\"\n",
    "        user_proxy = autogen.UserProxyAgent(\n",
    "            name=\"user_proxy\",\n",
    "            system_message=\"A proxy for the user.\",\n",
    "            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=10,\n",
    "            code_execution_config=False,\n",
    "        )\n",
    "\n",
    "        @user_proxy.register_for_execution()\n",
    "        @agent.register_for_llm(description=\"Weather forecats for a city\")\n",
    "        def weather_forecast(city: str) -> str:\n",
    "            return f\"The weather forecast for {city} is sunny.\"\n",
    "\n",
    "        # we will use a temporary directory as the cache path root to ensure fresh completion each time\n",
    "        with TemporaryDirectory() as cache_path_root:\n",
    "            with Cache.disk(cache_path_root=cache_path_root) as cache:\n",
    "                print(\n",
    "                    f\" - on_connect(): Initiating chat with agent {agent} using message '{initial_msg}'\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                user_proxy.initiate_chat(  # noqa: F704\n",
    "                    agent,\n",
    "                    message=initial_msg,\n",
    "                    cache=cache,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef868a",
   "metadata": {},
   "source": [
    "## Testing websockets server with Python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbe004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - test_setup() with websocket server running on ws://127.0.0.1:8765.\n",
      " - _handler(): Client connected on <websockets.sync.server.ServerConnection object at 0x7ff81ac93fa0>\n",
      " - Connected to server on ws://127.0.0.1:8765\n",
      " - on_connect(): Connected to client using IOWebsockets <autogen.io.websockets.IOWebsockets object at 0x7ff81acc0550>\n",
      " - on_connect(): Receiving message from client.\n",
      " - Sending message to server.\n",
      " - on_connect(): Initiating chat with agent <autogen.agentchat.conversable_agent.ConversableAgent object at 0x7ff81acc05e0> using message 'Check out the weather in Paris and write a poem about Paris taking the weather into consideration.'\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "Check out the weather in Paris and write a poem about Paris taking the weather into consideration.\n",
      "{\"type\":\"agent.llm_message\",\"content\":{\"sender\":\"user_proxy\",\"receiver\":\"chatbot\",\"message\":\"Check out the weather in Paris and write a poem about Paris taking the weather into consideration.\"}}\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool Call (call_I33Rsuac3zIdZUpbANLQAtAF): weather_forecast *****\u001b[0m\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "Arguments: \n",
      "{\"city\":\"Paris\"}\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "{\"type\":\"agent.suggest_tool_call\",\"content\":{\"sender\":\"chatbot\",\"receiver\":\"user_proxy\",\"function_name\":\"weather_forecast\",\"function_arguments\":\"{\\\"city\\\":\\\"Paris\\\"}\"}}\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION weather_forecast...\u001b[0m\n",
      "{\"type\":\"agent.executing_function_message\",\"content\":{\"executor\":\"user_proxy\",\"function_name\":\"weather_forecast\",\"function_args\":{\"city\":\"Paris\"}}}{\"type\":\"agent.executed_function_message\",\"content\":{\"executor\":\"user_proxy\",\"function_name\":\"weather_forecast\",\"function_args\":{\"city\":\"Paris\"},\"result\":\"The weather forecast for Paris is sunny.\"}}\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\u001b[32m***** Response from calling tool \"call_I33Rsuac3zIdZUpbANLQAtAF\" *****\u001b[0m\n",
      "The weather forecast for Paris is sunny.\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[32mSure, I will now write a poem about Paris with the sunny weather in mind. Let's get started.\u001b[0m\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "Sure, I will now write a poem about Paris with the sunny weather in mind. Let's get started.\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "{\"type\":\"agent.llm_message\",\"content\":{\"sender\":\"chatbot\",\"receiver\":\"user_proxy\",\"message\":\"Sure, I will now write a poem about Paris with the sunny weather in mind. Let's get started.\"}}\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[32mIn Paris, the sun shines bright,\n",
      "Gleaming on streets with pure delight.\n",
      "Golden rays on the Seine's embrace,\n",
      "A tranquil scene, a perfect place.\n",
      "\n",
      "Cafes buzz with laughter and cheer,\n",
      "As Parisians gather near and near.\n",
      "The Eiffel Tower stands tall and grand,\n",
      "Casting shadows on the sunlit land.\n",
      "\n",
      "Flowers bloom in parks so green,\n",
      "A picturesque sight, a serene dream.\n",
      "The sunny skies of Paris above,\n",
      "A city of beauty, grace, and love.\n",
      "\n",
      "TERMINATE\n",
      "TERMINATE\u001b[0m\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "In Paris, the sun shines bright,\n",
      "Gleaming on streets with pure delight.\n",
      "Golden rays on the Seine's embrace,\n",
      "A tranquil scene, a perfect place.\n",
      "\n",
      "Cafes buzz with laughter and cheer,\n",
      "As Parisians gather near and near.\n",
      "The Eiffel Tower stands tall and grand,\n",
      "Casting shadows on the sunlit land.\n",
      "\n",
      "Flowers bloom in parks so green,\n",
      "A picturesque sight, a serene dream.\n",
      "The sunny skies of Paris above,\n",
      "A city of beauty, grace, and love.\n",
      "\n",
      "TERMINATE\n",
      "TERMINATE\n",
      "\n",
      " - Received TERMINATE message. Exiting.\n"
     ]
    }
   ],
   "source": [
    "with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8765) as uri:\n",
    "    print(f\" - test_setup() with websocket server running on {uri}.\", flush=True)\n",
    "\n",
    "    with ws_connect(uri) as websocket:\n",
    "        print(f\" - Connected to server on {uri}\", flush=True)\n",
    "\n",
    "        print(\" - Sending message to server.\", flush=True)\n",
    "        # websocket.send(\"2+2=?\")\n",
    "        websocket.send(\n",
    "            \"Check out the weather in Paris and write a poem about Paris taking the weather into consideration.\"\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            message = websocket.recv()\n",
    "            message = message.decode(\"utf-8\") + \"\\n\" if isinstance(message, bytes) else message\n",
    "            # drop the newline character\n",
    "            # if message.endswith(\"\\n\"):\n",
    "            #     message = message[:-1]\n",
    "\n",
    "            print(message, end=\"\", flush=True)\n",
    "\n",
    "            if \"TERMINATE\" in message:\n",
    "                print()\n",
    "                print(\" - Received TERMINATE message. Exiting.\", flush=True)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a656564",
   "metadata": {},
   "source": [
    "## Testing websockets server running inside FastAPI server with HTML/JS client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e55dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager  # noqa: E402\n",
    "from pathlib import Path  # noqa: E402\n",
    "\n",
    "from fastapi import FastAPI  # noqa: E402\n",
    "from fastapi.responses import HTMLResponse  # noqa: E402\n",
    "\n",
    "PORT = 8000\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Autogen websocket test</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>WebSocket Chat</h1>\n",
    "        <form action=\"\" onsubmit=\"sendMessage(event)\">\n",
    "            <input type=\"text\" id=\"messageText\" autocomplete=\"off\"/>\n",
    "            <button>Send</button>\n",
    "        </form>\n",
    "        <ul id='messages'>\n",
    "        </ul>\n",
    "        <script>\n",
    "            var ws = new WebSocket(\"ws://localhost:8080/ws\");\n",
    "            ws.onmessage = function(event) {\n",
    "                var messages = document.getElementById('messages')\n",
    "                var message = document.createElement('li')\n",
    "                var content = document.createTextNode(event.data)\n",
    "                message.appendChild(content)\n",
    "                messages.appendChild(message)\n",
    "            };\n",
    "            function sendMessage(event) {\n",
    "                var input = document.getElementById(\"messageText\")\n",
    "                ws.send(input.value)\n",
    "                input.value = ''\n",
    "                event.preventDefault()\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def run_websocket_server(app):\n",
    "    with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:\n",
    "        print(f\"Websocket server started at {uri}.\", flush=True)\n",
    "\n",
    "        yield\n",
    "\n",
    "\n",
    "app = FastAPI(lifespan=run_websocket_server)\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def get():\n",
    "    return HTMLResponse(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92e50b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [41514]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websocket server started at ws://127.0.0.1:8080.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [41514]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn  # noqa: E402\n",
    "\n",
    "config = uvicorn.Config(app)\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()  # noqa: F704"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb50946",
   "metadata": {},
   "source": [
    "## Testing  websockets server with HTML/JS client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from http.server import HTTPServer, SimpleHTTPRequestHandler  # noqa: E402\n",
    "\n",
    "PORT = 8000\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Autogen websocket test</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>WebSocket Chat</h1>\n",
    "        <form action=\"\" onsubmit=\"sendMessage(event)\">\n",
    "            <input type=\"text\" id=\"messageText\" autocomplete=\"off\"/>\n",
    "            <button>Send</button>\n",
    "        </form>\n",
    "        <ul id='messages'>\n",
    "        </ul>\n",
    "        <script>\n",
    "            var ws = new WebSocket(\"ws://localhost:8080/ws\");\n",
    "            ws.onmessage = function(event) {\n",
    "                var messages = document.getElementById('messages')\n",
    "                var message = document.createElement('li')\n",
    "                var content = document.createTextNode(event.data)\n",
    "                message.appendChild(content)\n",
    "                messages.appendChild(message)\n",
    "            };\n",
    "            function sendMessage(event) {\n",
    "                var input = document.getElementById(\"messageText\")\n",
    "                ws.send(input.value)\n",
    "                input.value = ''\n",
    "                event.preventDefault()\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    # create a simple HTTP webpage\n",
    "    path = Path(temp_dir) / \"chat.html\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    #\n",
    "    class MyRequestHandler(SimpleHTTPRequestHandler):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, directory=temp_dir, **kwargs)\n",
    "\n",
    "        def do_GET(self):\n",
    "            if self.path == \"/\":\n",
    "                self.path = \"/chat.html\"\n",
    "            return SimpleHTTPRequestHandler.do_GET(self)\n",
    "\n",
    "    handler = MyRequestHandler\n",
    "\n",
    "    with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:\n",
    "        print(f\"Websocket server started at {uri}.\", flush=True)\n",
    "\n",
    "        with HTTPServer((\"\", PORT), handler) as httpd:\n",
    "            print(\"HTTP server started at http://localhost:\" + str(PORT))\n",
    "            httpd.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19656d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
